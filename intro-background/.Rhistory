options(scipen=999)
options(htmltools.dir.version = FALSE)
## RefManageR options
BibOptions(
bib.style = "authoryear",
hyperlink = "to.bib",
style = "markdown",
max.names = 3L
)
if (requireNamespace("bibtex")) {
file.name <- system.file("Bib", "test.bib", package="RefManageR")
bib <- ReadBib(file.name)
}
if (requireNamespace("bibtex")) {
file.name <- system.file("Bib", "test.bib", package="RefManageR")
bib <- ReadBib(file.name)
}
detach("package:bibtex", unload = TRUE)
library(bibtex)
## Save package names as a vector of strings
pkgs <-
c("rmarkdown",
"knitr",
"dplyr",
"devtools",
"widgetframe",
"RefManageR",
"bibtex",
"plotly")
## Install uninstalled packages
lapply(pkgs[!(pkgs %in% installed.packages())], install.packages)
## Load all packages to library and adjust options
lapply(pkgs, library, character.only = TRUE)
## Devtools install
if (!("icon" %in% installed.packages()))
devtools::install_github("ropenscilabs/icon")
library(icon)
## Global chunk options
knitr::opts_chunk$set(echo = FALSE,
warning = FALSE,
message = FALSE)
options(scipen=999)
options(htmltools.dir.version = FALSE)
## RefManageR options
BibOptions(
bib.style = "authoryear",
hyperlink = "to.bib",
style = "markdown",
max.names = 3L
)
if (requireNamespace("bibtex")) {
file.name <- system.file("Bib", "test.bib", package="RefManageR")
bib <- ReadBib(file.name)
}
file <- system.file("Bib", "test.bib", package = "RefManageR")
bib <- ReadBib(file, check = "error")
xaringan::inf_mr()
xaringan::inf_mr()
## Save package names as a vector of strings
pkgs <-
c("rmarkdown",
"knitr",
"dplyr",
"devtools",
"widgetframe",
"RefManageR",
"bibtex",
"plotly",
"xaringan")
## Install uninstalled packages
lapply(pkgs[!(pkgs %in% installed.packages())], install.packages)
## Load all packages to library and adjust options
lapply(pkgs, library, character.only = TRUE)
## Devtools install
if (!("icon" %in% installed.packages()))
devtools::install_github("ropenscilabs/icon")
library(icon)
## Global chunk options
knitr::opts_chunk$set(echo = FALSE,
warning = FALSE,
message = FALSE)
options(scipen=999)
options(htmltools.dir.version = FALSE)
## RefManageR options
BibOptions(
bib.style = "authoryear",
hyperlink = "to.bib",
style = "markdown",
max.names = 3L
)
file <- system.file("Bib", "test.bib", package = "RefManageR")
bib <- ReadBib(file, check = "error")
View(bib)
## Save package names as a vector of strings
pkgs <-
c("rmarkdown",
"knitr",
"dplyr",
"devtools",
"widgetframe",
"RefManageR",
"bibtex",
"plotly")
## Install uninstalled packages
lapply(pkgs[!(pkgs %in% installed.packages())], install.packages)
## Load all packages to library and adjust options
lapply(pkgs, library, character.only = TRUE)
## Devtools install
if (!("icon" %in% installed.packages()))
devtools::install_github("ropenscilabs/icon")
library(icon)
## Global chunk options
knitr::opts_chunk$set(echo = FALSE,
warning = FALSE,
message = FALSE)
options(scipen=999)
options(htmltools.dir.version = FALSE)
## RefManageR options
BibOptions(
bib.style = "authoryear",
hyperlink = "to.bib",
style = "markdown",
max.names = 3L
)
file <- system.file("Bib", "biblatexExamples.bib", package = "RefManageR")
bib <- ReadBib(file, check = "error")
View(bib)
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
knitr::opts_knit$set(root.dir = 'C:/Users/camil/Desktop/ted-talks-STM') #set working directory
set.seed(1337)
if(!require("tidyverse")) {install.packages("tidyverse"); library("tidyverse")}
if(!require("quanteda")) {install.packages("quanteda"); library("quanteda")}
if(!require("tidytext")) {install.packages("tidytex"); library("tidytext")}
if(!require("stm")) {install.packages("stm"); library("stm")}
if(!require("stminsights")) {install.packages("stminsights"); library("stminsights")}
if(!require("lubridate")) {install.packages("lubridate"); library("lubridate")}
if(!require("ggplot2")) {install.packages("ggplot2"); library("ggplot2")}
if(!require("cowplot")) {install.packages("cowplot"); library("cowplot")}
#library(ggrepel)
#library(ggeffects)
#library(sjPlot)
#library(stargazer)
#library(graphics)
#library(ggthemes)
#library(scales)
theme_set(theme_light()) #set global theme
options(scipen=999) #force R not to use exponential notation (e.g. e+10)
theme_set(theme_light()) #set global theme
options(scipen=999) #force R not to use exponential notation (e.g. e+10)
df <- read_tsv('C:/Users/camil/Desktop/CSS Session/ted_main_dataset.tsv')
df <- df %>%
filter(!is.na(speaker_image_nr_faces)) %>% # remove talks without human speakers
arrange(date) #order by date
df$year <- str_sub(df$date, 1, 4) #extract year
df$date_num <- factor(df$date) %>% as.numeric() # turn date variable from character to numeric
df <- df %>%
mutate(id = 1:n()) %>% #add numeric ID for each talk
select(id, date_num, year, title, text, dummy_female, dummy_white) #select relevant variables
head(df, 5)
ted_corpus <- corpus(df$text)
ted_corpus
ted_corpus[1:5]
# with quanteda (combines cleaning and casting in one step)
ted_dfm <- dfm(ted_corpus,
stem = TRUE,
tolower = TRUE,
remove_twitter = FALSE,
remove_punct = TRUE,
remove_url = FALSE,
remove_numbers =TRUE,
verbose = TRUE,
remove = stopwords('english'))
# with quanteda (combines cleaning and casting in one step)
ted_dfm <- dfm(ted_corpus,
stem = TRUE,
tolower = TRUE,
remove_punct = TRUE,
remove_numbers =TRUE,
verbose = TRUE,
remove = stopwords('english'))
# with quanteda (combines cleaning and casting in one step)
ted_dfm <- dfm(ted_corpus,
stem = TRUE,
tolower = TRUE,
remove_punct = TRUE,
remove_numbers =TRUE,
verbose = TRUE,
remove = stopwords('english'))
ted_dfm #check that stemming etc worked
dim(ted_dfm)
ted_dfm #check that stemming etc worked
dim(ted_dfm)
ted_dfm <- dfm_trim(ted_dfm, max_docfreq = 0.50,min_docfreq = 0.01,
docfreq_type = 'prop')
dim(ted_dfm) # 2333 documents with 4805 features (previous: 44727)
out <- convert(ted_dfm, to = "stm", docvars=df)
str(out, max.level = 1)
load("C:/Users/camil/Desktop/CSS Session/ted_first_model.RData")
# plot topics with most frequent words within topics
plot(stm_20)
# By using summary() you receive top words for all 20 topics
summary(stm_20)
# By using summary() you receive top words for all 20 topics
summary(stm_20[1:5])
# By using summary() you receive top words for all 20 topics
summary(stm_20[,1:5])
# By using summary() you receive top words for all 20 topics
summary(stm_20[1:5,])
# fit regression
effect_stm_20 <- estimateEffect(1:20 ~ s(date_num, degree = 2) +
dummy_female * dummy_white,
stm_20,
metadata = out$meta)
#summary() gives you regression coefficients for all 20 topics
summary(effect_stm_20)
load("C:/Users/camil/Desktop/CSS Session/ted_all_topic_models.RData")
#extract objects for single k values to perform regression and other analysis
stm20<-stm_20_30_40_50[[1,2]]
stm30<-stm_20_30_40_50[[2,2]]
stm40<-stm_20_30_40_50[[3,2]]
stm50<-stm_20_30_40_50[[4,2]]
stm50
# calculate exclusivity + semantic coherence
model_scores <- stm_20_30_40_50 %>%
mutate(exclusivity = map(model, exclusivity),
semantic_coherence = map(model, semanticCoherence, out$documents)) %>%
select(K, exclusivity, semantic_coherence)
# calculate exclusivity + semantic coherence
model_scores <- stm_20_30_40_50 %>%
mutate(exclusivity = map(model, exclusivity),
semantic_coherence = map(model, semanticCoherence, out$documents)) %>%
select(K, exclusivity, semantic_coherence)
model_scores #results in nested dataframes containing the quantities of interest
# plot
model_scores %>%
select(K, exclusivity, semantic_coherence) %>%
filter(K %in% c(20, 30, 50)) %>%
unnest() %>%
mutate(K = as.factor(K)) %>%
ggplot(aes(semantic_coherence, exclusivity, color = K)) +
geom_point(size = 2, alpha = 0.7) +
labs(x = "Semantic coherence",
y = "Exclusivity",
title = "Comparing exclusivity and semantic coherence")
# plot means for better overview
model_scores %>%
unnest(c(exclusivity, semantic_coherence)) %>%
group_by(K) %>%
summarize(exclusivity = mean(exclusivity),
semantic_coherence = mean(semantic_coherence)) %>%
ggplot(aes(x = semantic_coherence, y = exclusivity, color = as.factor(K))) +
geom_point() +
theme_bw()
# getting semantic coherence and exclusivity scores
quality <-
get_diag(
models = list(
model_20 = stm20[[1]],
model_30 = stm30[[1]],
model_50 = stm50[[1]]
),
outobj = out
)
# getting semantic coherence and exclusivity scores
quality <-
get_diag(
models = list(
model_20 = stm20[[1]],
model_30 = stm30[[1]],
model_50 = stm50[[1]]
),
outobj = out
)
# plotting scores (figure S2)
quality %>%
mutate(nr_topics = as.factor(nr_topics)) %>%
ggplot(aes(
x = coherence,
y = exclusivity,
color = statistic,
shape = nr_topics
))  +
geom_text_repel(aes(label = nr_topics),
size = 4.5,
show.legend = FALSE) + geom_point() +
labs(
x = 'Semantic Coherence',
y = 'Exclusivity',
shape = 'No. of topics',
color = 'Statistic'
) + theme_light() +
theme(
legend.position = c(0.9, 0.7),
legend.background = element_rect(color = "grey50")
) +
scale_color_brewer(palette = 'Set1')
td_beta <- tidy(stm30[[1]])
td_beta
td_beta %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
mutate(topic = paste0("Topic ", topic),
term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(alpha = 0.8, show.legend = FALSE) +
facet_wrap(~ topic, scales = "free_y") +
coord_flip() +
scale_x_reordered() +
labs(x = NULL, y = expression(beta),
title = "Highest word probabilities for each topic",
subtitle = "Different words are associated with different topics")
td_gamma <- tidy(stm30[[1]], matrix = "gamma",
document_names = rownames(ted_dfm))
top_terms <- td_beta %>%
arrange(beta) %>%
group_by(topic) %>%
top_n(7, beta) %>%
arrange(-beta) %>%
select(topic, term) %>%
summarise(terms = list(term)) %>%
mutate(terms = map(terms, paste, collapse = ", ")) %>%
unnest()
gamma_terms <- td_gamma %>%
group_by(topic) %>%
summarise(gamma = mean(gamma)) %>%
arrange(desc(gamma)) %>%
left_join(top_terms, by = "topic") %>%
mutate(topic = paste0("Topic ", topic),
topic = reorder(topic, gamma))
gamma_terms %>%
top_n(20, gamma) %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust = 0, nudge_y = 0.0005, size = 3,
family = "IBMPlexSans") +
coord_flip() +
scale_y_continuous(expand = c(0,0),
limits = c(0, 0.09),
labels = percent_format()) +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "Top 20 topics by prevalence in the Hacker News corpus",
subtitle = "With the top words that contribute to each topic")
gamma_terms %>%
top_n(20, gamma) %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust = 0, nudge_y = 0.0005, size = 3,
family = "IBMPlexSans") +
coord_flip() +
scale_y_continuous(expand = c(0,0),
limits = c(0, 0.09),
labels = percent_format()) +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "Top 20 topics by prevalence in the Hacker News corpus",
subtitle = "With the top words that contribute to each topic")
if(!require("scales")) {install.packages("scales"); library("scales")}
gamma_terms %>%
top_n(20, gamma) %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust = 0, nudge_y = 0.0005, size = 3,
family = "IBMPlexSans") +
coord_flip() +
scale_y_continuous(expand = c(0,0),
limits = c(0, 0.09),
labels = percent_format()) +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "Top 20 topics by prevalence in the Hacker News corpus",
subtitle = "With the top words that contribute to each topic")
if(!require("ggthemes")) {install.packages("ggthemes"); library("ggthemes")}
gamma_terms %>%
top_n(20, gamma) %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust = 0, nudge_y = 0.0005, size = 3,
family = "IBMPlexSans") +
coord_flip() +
scale_y_continuous(expand = c(0,0),
limits = c(0, 0.09),
labels = percent_format()) +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "Top 20 topics by prevalence in the Hacker News corpus",
subtitle = "With the top words that contribute to each topic")
# tabular format
gamma_terms %>%
select(topic, gamma, terms) %>%
knitr::kable(digits = 3,
col.names = c("Topic", "Expected topic proportion", "Top 7 terms"))
# tabular format
gamma_terms %>%
select(topic, gamma, terms) %>%
knitr::kable(digits = 3,
col.names = c("Topic", "Expected topic proportion", "Top 7 terms"))
td_gamma
df <- read_tsv('C:/Users/camil/Desktop/CSS Session/ted_main_dataset.tsv')
df <- df %>%
filter(!is.na(speaker_image_nr_faces)) %>% # remove talks without human speakers
arrange(date) #order by date
#df$date_num <- factor(df$date) %>% as.numeric() # turn date variable from character to numeric
df <- df %>%
date_num <- as.numeric(factor(df$date)) %>%
mutate(id = 1:n()) %>% #add numeric ID for each talk
select(id, date_num, title, text, dummy_female, dummy_white) #select relevant variables
df <- read_tsv('C:/Users/camil/Desktop/CSS Session/ted_main_dataset.tsv')
df <- df %>%
filter(!is.na(speaker_image_nr_faces)) %>% # remove talks without human speakers
arrange(date) #order by date
#df$date_num <- factor(df$date) %>% as.numeric() # turn date variable from character to numeric
df <- df %>%
date_num <- factor(date) %>%
date_num <- as.numeric(date_num) %>%
mutate(id = 1:n()) %>% #add numeric ID for each talk
select(id, date_num, title, text, dummy_female, dummy_white) #select relevant variables
df <- read_tsv('C:/Users/camil/Desktop/CSS Session/ted_main_dataset.tsv')
df <- df %>%
filter(!is.na(speaker_image_nr_faces)) %>% # remove talks without human speakers
arrange(date) #order by date
#df$date_num <- factor(df$date) %>% as.numeric() # turn date variable from character to numeric
df <- df %>%
date_num = factor(date) %>%
date_num = as.numeric(date_num) %>%
mutate(id = 1:n()) %>% #add numeric ID for each talk
select(id, date_num, title, text, dummy_female, dummy_white) #select relevant variables
df <- read_tsv('C:/Users/camil/Desktop/CSS Session/ted_main_dataset.tsv')
df <- df %>%
filter(!is.na(speaker_image_nr_faces)) %>% # remove talks without human speakers
arrange(date) #order by date
#df$date_num <- factor(df$date) %>% as.numeric() # turn date variable from character to numeric
df <- df %>%
date_num = factor(date) %>%
mutate(id = 1:n()) %>% #add numeric ID for each talk
select(id, date_num, title, text, dummy_female, dummy_white) #select relevant variables
df <- read_tsv('C:/Users/camil/Desktop/CSS Session/ted_main_dataset.tsv')
df <- df %>%
filter(!is.na(speaker_image_nr_faces)) %>% # remove talks without human speakers
arrange(date) #order by date
df$date_num <- factor(df$date) %>% as.numeric() # turn date variable from character to numeric
df <- df %>%
mutate(id = 1:n()) %>% #add numeric ID for each talk
select(id, date_num, title, text, dummy_female, dummy_white) #select relevant variables
head(df, 5)
devtools::install_github("hadley/emo")
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
## Save package names as a vector of strings
pkgs <-
c("rmarkdown",
"knitr",
"dplyr",
"devtools",
"widgetframe",
"RefManageR",
"bibtex",
"plotly",
"xaringan")
## Install uninstalled packages
lapply(pkgs[!(pkgs %in% installed.packages())], install.packages)
## Load all packages to library and adjust options
lapply(pkgs, library, character.only = TRUE)
## Devtools install
#if (!("icon" %in% installed.packages()))
# devtools::install_github("ropenscilabs/icon")
#library(icon)
## Global chunk options
knitr::opts_chunk$set(echo = FALSE,
warning = FALSE,
message = FALSE)
options(scipen=999)
options(htmltools.dir.version = FALSE)
## RefManageR options
BibOptions(
bib.style = "authoryear",
hyperlink = "to.bib",
style = "markdown",
max.names = 3L
)
knitr::include_graphics("wordcloud_2.PNG")
knitr::include_graphics("wordcloud_1.PNG")
knitr::include_graphics("wordcloud_3.PNG")
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
xaringan::inf_mr()
# By using summary() you receive top words for all 20 topics
summary(stm30[[1]])
